---
title: "Lab 7"
author: "Donald Elrod"
date: "May 3, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1
```{r}
th = (1:39)/40
p.th = sqrt(th)
th.hat.1=th.hat.2=MSE1=MSE2=0
for (i in 1:39) {
  for (j in 1:10000) {
    samp <- rbinom(100, 2, p.th[i])
    th.hat.1[j] = mean(samp)/2
    th.hat.1[j] = th.hat.1[j]^2
    th.hat.2[j] = mean(samp==2)
  }
  mth1 = (th.hat.1 - th[i])^2
  mth2 = (th.hat.2 - th[i])^2
  MSE1[i] = mean(mth1)
  MSE2[i] = mean(mth2)
}

```

# Question 2
```{r}
ymax = max(MSE1, MSE2)
```

# Question 3
```{r}
plot(th,MSE1,col='blue',ylim=c(0,ymax))
```

# Question 4
```{r}
plot(th,MSE2,col='red',ylim=c(0,ymax))
```

# Question 5
```{r}
plot(th, MSE1, col='blue', ylim=c(0, ymax), xlab = 'th', ylab = 'MSE values')
points(th, MSE2, col='red')
```
```{r}
summary(MSE1)
summary(MSE2)
```


Since $\theta_1$ has overall lower values, it is closer to being uniform than $\theta_2$ so therefore $\theta_1$ is the better estimation procedure

# Question 6
```{r}
th.2 = (1:37)/40
p.th.2 = sqrt( (40*th.2-1)/36)
th.hat.1.2=th.hat.2.2=MSE1.2=MSE2.2=0
for (i in 1:37) {
  for (j in 1:10000) {
    pop = rep(c(p.th.2[i], 0.5), c(9,1))
    random.p = sample(pop, size=100, replace=T)
    samp.2 = rbinom(100, 2, random.p)
    th.hat.1.2[j] = mean(samp.2)/2
    th.hat.1.2[j] = th.hat.1.2[j]^2
    th.hat.2.2[j] = mean(samp.2==2)
  }
  mth1.2 = (th.hat.1.2 - th.2[i])^2
  mth2.2 = (th.hat.2.2 - th.2[i])^2
  MSE1.2[i] = mean(mth1.2)
  MSE2.2[i] = mean(mth2.2)
}

ymax.2 = max(MSE1.2, MSE2.2)

plot(th.2, MSE1.2, col='blue', ylim=c(0, ymax.2), xlab = 'th', ylab = 'MSE values')
points(th.2, MSE2.2, col='red')
```

# Question 7
```{r}
summary(MSE1.2)
summary(MSE2.2)
```


It seems that in this case, $\theta_2$ is larger at first but then slopes sharply below $\theta_1$, while $\theta_1$ remains semi-flat in its curve as th $\rightarrow$ 1. Due to this, I looked at the summary of MSE1.2 and MSE2.2, and it seems as though $\theta_1$ is a slightly better approximation due to its lower mean error, however the difference in error is very small and it seems as though, in some cases, $\theta_2$ would be a better model to approximate by


